#!/usr/bin/env python3
"""
ğŸ¤– Ø§Ù„Ø°ÙƒÙŠ - Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ù…Ø¬Ø§Ù†ÙŠ Ø§Ù„Ù…Ø·ÙˆØ± Ù…Ù‡Ù†ÙŠØ§Ù‹
Al-Thaki - Professional Free Offline AI Assistant

Enterprise-grade features:
- Offline-first architecture
- Production-ready code
- Enterprise security
- Scalable design
- Multi-language support
- Advanced caching
- Error handling & logging
- Performance monitoring

Version: 1.0.0
Author: Your Name
License: MIT
"""

import streamlit as st
import os
import sys
import json
import time
import hashlib
import sqlite3
import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any, Union
from dataclasses import dataclass, asdict
from contextlib import contextmanager
import threading
from concurrent.futures import ThreadPoolExecutor
import queue

# Third-party imports with graceful fallbacks
try:
    import torch
    from transformers import (
        AutoModelForCausalLM, 
        AutoTokenizer, 
        pipeline,
        set_seed
    )
    from sentence_transformers import SentenceTransformer
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False
    st.warning("âš ï¸ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© ØºÙŠØ± Ù…ØªÙˆÙØ±Ø©. Ø³ÙŠØ¹Ù…Ù„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¨Ø§Ù„Ù†Ù…Ø· Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ.")

try:
    import pandas as pd
    import numpy as np
    PANDAS_AVAILABLE = True
except ImportError:
    PANDAS_AVAILABLE = False

try:
    import plotly.express as px
    import plotly.graph_objects as go
    PLOTLY_AVAILABLE = True
except ImportError:
    PLOTLY_AVAILABLE = False

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('app.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Configuration
@dataclass
class AppConfig:
    """Application configuration"""
    APP_NAME: str = "Ø§Ù„Ø°ÙƒÙŠ - Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ù…Ø¬Ø§Ù†ÙŠ"
    VERSION: str = "1.0.0"
    MAX_HISTORY: int = 100
    MAX_RESPONSE_LENGTH: int = 1000
    CACHE_TTL: int = 3600  # 1 hour
    DB_PATH: str = "data/assistant.db"
    MODELS_PATH: str = "data/models"
    CACHE_PATH: str = "data/cache"
    
    # Model configurations
    DEFAULT_MODEL: str = "microsoft/DialoGPT-small"  # Smaller for Streamlit Cloud
    EMBEDDING_MODEL: str = "sentence-transformers/all-MiniLM-L6-v2"
    
    # UI Configuration
    THEME_COLOR: str = "#667eea"
    SECONDARY_COLOR: str = "#764ba2"
    
    # Security
    SESSION_TIMEOUT: int = 3600 * 24  # 24 hours
    MAX_INPUT_LENGTH: int = 2000

class SecurityManager:
    """Enterprise-grade security manager"""
    
    @staticmethod
    def sanitize_input(text: str) -> str:
        """Sanitize user input"""
        if not text:
            return ""
        
        # Remove dangerous characters
        dangerous_chars = ['<', '>', '{', '}', '[', ']', '`', '|']
        for char in dangerous_chars:
            text = text.replace(char, '')
        
        # Limit length
        return text[:AppConfig.MAX_INPUT_LENGTH]
    
    @staticmethod
    def generate_session_id() -> str:
        """Generate secure session ID"""
        timestamp = str(time.time())
        random_data = os.urandom(16).hex()
        return hashlib.sha256(f"{timestamp}{random_data}".encode()).hexdigest()[:16]
    
    @staticmethod
    def is_session_valid(session_created: datetime) -> bool:
        """Check if session is still valid"""
        return datetime.now() - session_created < timedelta(seconds=AppConfig.SESSION_TIMEOUT)

class DatabaseManager:
    """Professional database management"""
    
    def __init__(self, db_path: str):
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        self._init_database()
        self._lock = threading.Lock()
    
    def _init_database(self):
        """Initialize database with proper schema"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.execute("PRAGMA foreign_keys = ON")
                
                # Sessions table
                conn.execute("""
                    CREATE TABLE IF NOT EXISTS sessions (
                        id TEXT PRIMARY KEY,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        last_activity TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        metadata TEXT
                    )
                """)
                
                # Conversations table
                conn.execute("""
                    CREATE TABLE IF NOT EXISTS conversations (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        session_id TEXT,
                        role TEXT NOT NULL,
                        content TEXT NOT NULL,
                        timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        metadata TEXT,
                        FOREIGN KEY (session_id) REFERENCES sessions (id)
                    )
                """)
                
                # Performance metrics
                conn.execute("""
                    CREATE TABLE IF NOT EXISTS metrics (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        metric_name TEXT NOT NULL,
                        metric_value REAL NOT NULL,
                        timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        session_id TEXT
                    )
                """)
                
                # Create indexes for performance
                conn.execute("CREATE INDEX IF NOT EXISTS idx_conversations_session ON conversations(session_id)")
                conn.execute("CREATE INDEX IF NOT EXISTS idx_conversations_timestamp ON conversations(timestamp)")
                
                conn.commit()
                logger.info("Database initialized successfully")
                
        except Exception as e:
            logger.error(f"Database initialization error: {e}")
            raise
    
    @contextmanager
    def get_connection(self):
        """Thread-safe database connection"""
        with self._lock:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            try:
                yield conn
            finally:
                conn.close()
    
    def save_message(self, session_id: str, role: str, content: str, metadata: dict = None):
        """Save message with error handling"""
        try:
            with self.get_connection() as conn:
                conn.execute("""
                    INSERT INTO conversations (session_id, role, content, metadata)
                    VALUES (?, ?, ?, ?)
                """, (session_id, role, content, json.dumps(metadata or {})))
                conn.commit()
                
                # Update session activity
                conn.execute("""
                    INSERT OR REPLACE INTO sessions (id, last_activity)
                    VALUES (?, CURRENT_TIMESTAMP)
                """, (session_id,))
                conn.commit()
                
        except Exception as e:
            logger.error(f"Error saving message: {e}")
    
    def get_conversation_history(self, session_id: str, limit: int = 50) -> List[Dict]:
        """Retrieve conversation history"""
        try:
            with self.get_connection() as conn:
                cursor = conn.execute("""
                    SELECT role, content, timestamp, metadata
                    FROM conversations 
                    WHERE session_id = ?
                    ORDER BY timestamp DESC
                    LIMIT ?
                """, (session_id, limit))
                
                return [dict(row) for row in cursor.fetchall()][::-1]  # Reverse for chronological order
                
        except Exception as e:
            logger.error(f"Error retrieving history: {e}")
            return []
    
    def save_metric(self, metric_name: str, value: float, session_id: str = None):
        """Save performance metrics"""
        try:
            with self.get_connection() as conn:
                conn.execute("""
                    INSERT INTO metrics (metric_name, metric_value, session_id)
                    VALUES (?, ?, ?)
                """, (metric_name, value, session_id))
                conn.commit()
        except Exception as e:
            logger.error(f"Error saving metric: {e}")

class ModelManager:
    """Professional AI model management"""
    
    def __init__(self, config: AppConfig):
        self.config = config
        self.models = {}
        self.model_locks = {}
        self._setup_paths()
    
    def _setup_paths(self):
        """Setup model storage paths"""
        self.models_path = Path(self.config.MODELS_PATH)
        self.cache_path = Path(self.config.CACHE_PATH)
        
        for path in [self.models_path, self.cache_path]:
            path.mkdir(parents=True, exist_ok=True)
    
    @st.cache_resource
    def load_models(_self):
        """Load models with caching and error handling"""
        if not TRANSFORMERS_AVAILABLE:
            return _self._load_fallback_models()
        
        models = {}
        
        try:
            progress_bar = st.progress(0, text="ğŸ”„ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬...")
            
            # Set random seed for reproducibility
            set_seed(42)
            
            # Load chat model
            progress_bar.progress(20, text="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©...")
            logger.info("Loading chat model...")
            
            models['chat'] = {
                'tokenizer': AutoTokenizer.from_pretrained(
                    _self.config.DEFAULT_MODEL,
                    cache_dir=str(_self.cache_path),
                    local_files_only=False
                ),
                'model': AutoModelForCausalLM.from_pretrained(
                    _self.config.DEFAULT_MODEL,
                    cache_dir=str(_self.cache_path),
                    local_files_only=False,
                    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
                    device_map="auto" if torch.cuda.is_available() else None
                )
            }
            
            # Set padding token
            if models['chat']['tokenizer'].pad_token is None:
                models['chat']['tokenizer'].pad_token = models['chat']['tokenizer'].eos_token
            
            progress_bar.progress(60, text="ğŸ” ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¨Ø­Ø«...")
            
            # Load embedding model
            try:
                models['embedding'] = SentenceTransformer(
                    _self.config.EMBEDDING_MODEL,
                    cache_folder=str(_self.cache_path)
                )
                logger.info("Embedding model loaded successfully")
            except Exception as e:
                logger.warning(f"Could not load embedding model: {e}")
                models['embedding'] = None
            
            progress_bar.progress(90, text="âš¡ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡...")
            
            # Optimize for inference
            models['chat']['model'].eval()
            
            if torch.cuda.is_available():
                try:
                    models['chat']['model'] = models['chat']['model'].half()
                    logger.info("Model optimized for GPU")
                except:
                    logger.info("GPU optimization failed, using CPU")
            
            progress_bar.progress(100, text="âœ… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¬Ø§Ù‡Ø²Ø©!")
            time.sleep(1)
            progress_bar.empty()
            
            logger.info("All models loaded successfully")
            st.success("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¨Ù†Ø¬Ø§Ø­! Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¬Ø§Ù‡Ø² Ù„Ù„Ø¹Ù…Ù„ Ø£ÙˆÙ Ù„Ø§ÙŠÙ†.")
            
            return models
            
        except Exception as e:
            logger.error(f"Error loading models: {e}")
            st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬: {str(e)}")
            return _self._load_fallback_models()
    
    def _load_fallback_models(self):
        """Load basic models as fallback"""
        logger.info("Loading fallback models...")
        return {
            'chat': None,
            'embedding': None,
            'fallback': True
        }
    
    def generate_response(self, prompt: str, history: List[Dict] = None, **kwargs) -> str:
        """Generate AI response with professional error handling"""
        start_time = time.time()
        
        try:
            if not self.models or self.models.get('fallback'):
                return self._generate_fallback_response(prompt, history)
            
            # Prepare context
            context = self._prepare_context(prompt, history or [])
            
            # Tokenize
            inputs = self.models['chat']['tokenizer'].encode(
                context + self.models['chat']['tokenizer'].eos_token,
                return_tensors='pt',
                max_length=512,
                truncation=True,
                padding=True
            )
            
            # Generate
            with torch.no_grad():
                outputs = self.models['chat']['model'].generate(
                    inputs,
                    max_new_tokens=min(200, self.config.MAX_RESPONSE_LENGTH),
                    temperature=kwargs.get('temperature', 0.7),
                    do_sample=True,
                    top_p=kwargs.get('top_p', 0.9),
                    top_k=kwargs.get('top_k', 50),
                    pad_token_id=self.models['chat']['tokenizer'].eos_token_id,
                    no_repeat_ngram_size=3,
                    early_stopping=True
                )
            
            # Decode response
            response = self.models['chat']['tokenizer'].decode(
                outputs[0][inputs.shape[-1]:],
                skip_special_tokens=True
            )
            
            response = response.strip()
            
            # Log metrics
            generation_time = time.time() - start_time
            if hasattr(st.session_state, 'db'):
                st.session_state.db.save_metric("generation_time", generation_time)
                st.session_state.db.save_metric("response_length", len(response))
            
            # Validate response
            if len(response) < 10 or not response:
                return self._generate_fallback_response(prompt, history)
            
            return response[:self.config.MAX_RESPONSE_LENGTH]
            
        except Exception as e:
            logger.error(f"Error generating response: {e}")
            return self._generate_fallback_response(prompt, history)
    
    def _prepare_context(self, prompt: str, history: List[Dict]) -> str:
        """Prepare conversation context"""
        context_parts = []
        
        # Add recent history (last 3 exchanges)
        for msg in history[-6:]:  # 3 user + 3 assistant messages
            role = "User" if msg['role'] == 'user' else "Assistant"
            context_parts.append(f"{role}: {msg['content']}")
        
        # Add current prompt
        context_parts.append(f"User: {prompt}")
        context_parts.append("Assistant:")
        
        return "\n".join(context_parts)
    
    def _generate_fallback_response(self, prompt: str, history: List[Dict] = None) -> str:
        """Generate intelligent fallback responses"""
        prompt_lower = prompt.lower()
        
        # Greeting responses
        greetings = ['Ù…Ø±Ø­Ø¨Ø§', 'Ø§Ù„Ø³Ù„Ø§Ù…', 'hello', 'hi', 'Ø£Ù‡Ù„Ø§']
        if any(word in prompt_lower for word in greetings):
            return """ğŸ¤– Ø£Ù‡Ù„Ø§Ù‹ ÙˆØ³Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ù…Ø¬Ø§Ù†ÙŠ!

**âœ¨ Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª Ø§Ù„ÙØ±ÙŠØ¯Ø©:**
â€¢ ğŸ”’ Ø®ØµÙˆØµÙŠØ© Ù…Ø·Ù„Ù‚Ø© - Ø¨ÙŠØ§Ù†Ø§ØªÙƒ Ø¢Ù…Ù†Ø© Ø¹Ù„Ù‰ Ø¬Ù‡Ø§Ø²Ùƒ
â€¢ ğŸŒ ÙŠØ¹Ù…Ù„ Ø£ÙˆÙ Ù„Ø§ÙŠÙ† Ø¨Ø¹Ø¯ Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£ÙˆÙ„ÙŠ
â€¢ ğŸ†“ Ù…Ø¬Ø§Ù†ÙŠ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ - Ø¨Ø¯ÙˆÙ† Ø§Ø´ØªØ±Ø§ÙƒØ§Øª
â€¢ ğŸ‡¸ğŸ‡¦ Ø¯Ø¹Ù… Ù…ØªÙ‚Ø¯Ù… Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©

**ğŸ’¡ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ:**
â€¢ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø¹Ø§Ù…Ø©
â€¢ ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙˆØ§Ù„Ù…Ù‚Ø§Ù„Ø§Øª
â€¢ Ø§Ù„Ø´Ø±Ø­ ÙˆØ§Ù„ØªØ¹Ù„ÙŠÙ…
â€¢ Ø§Ù„Ø¹ØµÙ Ø§Ù„Ø°Ù‡Ù†ÙŠ ÙˆØ§Ù„Ø£ÙÙƒØ§Ø± Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹ÙŠØ©
â€¢ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙŠ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹

ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø§Ù„ÙŠÙˆÙ…ØŸ ğŸ˜Š"""

        # Question responses
        question_words = ['Ù…Ø§Ø°Ø§', 'ÙƒÙŠÙ', 'Ù…ØªÙ‰', 'Ø£ÙŠÙ†', 'Ù„Ù…Ø§Ø°Ø§', 'what', 'how', 'when', 'where', 'why']
        if any(word in prompt_lower for word in question_words):
            return f"""Ø´ÙƒØ±Ø§Ù‹ Ù„Ø³Ø¤Ø§Ù„Ùƒ Ø§Ù„Ù…Ø«ÙŠØ±: "{prompt[:100]}..."

**ğŸ¤– ÙƒÙ…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù…ØªØ·ÙˆØ±ØŒ Ø£Ø³ØªØ·ÙŠØ¹ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ:**

**ğŸ“š Ø§Ù„ØªØ¹Ù„ÙŠÙ… ÙˆØ§Ù„Ø´Ø±Ø­:**
â€¢ ØªØ¨Ø³ÙŠØ· Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©
â€¢ Ø´Ø±Ø­ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹Ø§Øª Ø¨Ø·Ø±Ù‚ Ù…Ø®ØªÙ„ÙØ©
â€¢ ØªÙ‚Ø¯ÙŠÙ… Ø£Ù…Ø«Ù„Ø© Ø¹Ù…Ù„ÙŠØ©

**âœï¸ Ø§Ù„ÙƒØªØ§Ø¨Ø© ÙˆØ§Ù„Ø¥Ø¨Ø¯Ø§Ø¹:**
â€¢ ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª ÙˆØ§Ù„Ù…Ø­ØªÙˆÙ‰
â€¢ ØªØ­Ø±ÙŠØ± ÙˆØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†ØµÙˆØµ
â€¢ Ø§Ù„Ø¹ØµÙ Ø§Ù„Ø°Ù‡Ù†ÙŠ Ù„Ù„Ø£ÙÙƒØ§Ø±

**ğŸ’¼ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ù‡Ù†ÙŠØ©:**
â€¢ ÙƒØªØ§Ø¨Ø© Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ©
â€¢ Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø¹Ù…Ù„
â€¢ Ø®Ø·Ø· Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹

**ğŸ” Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ Ø¥Ø¬Ø§Ø¨Ø©:**
â€¢ ÙƒÙ† Ø£ÙƒØ«Ø± ØªØ­Ø¯ÙŠØ¯Ø§Ù‹ ÙÙŠ Ø³Ø¤Ø§Ù„Ùƒ
â€¢ Ø£Ø¶Ù Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
â€¢ Ø§Ø°ÙƒØ± Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ù‡Ù…Ø©

**ğŸŒŸ Ù…ÙŠØ²Ø© Ø®Ø§ØµØ©:** Ø£Ø¹Ù…Ù„ Ù…Ø­Ù„ÙŠØ§Ù‹ Ø¨Ø¯ÙˆÙ† Ø¥Ù†ØªØ±Ù†ØªØŒ ÙØ®ØµÙˆØµÙŠØªÙƒ Ù…Ø­Ù…ÙŠØ© Ø¨Ø§Ù„ÙƒØ§Ù…Ù„!

Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØ© Ø³Ø¤Ø§Ù„Ùƒ Ø¨ØªÙØ§ØµÙŠÙ„ Ø£ÙƒØ«Ø± Ù„Ø£Ø¹Ø·ÙŠÙƒ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù…Ø«Ù„Ù‰ØŸ"""

        # Default intelligent response
        return f"""Ø´ÙƒØ±Ø§Ù‹ Ù„Ùƒ Ø¹Ù„Ù‰ "{prompt[:100]}..."

**ğŸ§  ÙƒÙ…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù…Ø­ØªØ±Ù:**

**ğŸ’¡ ÙÙ‡Ù…ÙŠ Ù„Ø·Ù„Ø¨Ùƒ:**
Ø£Ø±Ù‰ Ø£Ù†Ùƒ ØªØ­ØªØ§Ø¬ Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙŠ Ù…ÙˆØ¶ÙˆØ¹ Ù…Ø¹ÙŠÙ†ØŒ ÙˆØ£Ù†Ø§ Ù‡Ù†Ø§ Ù„Ø£Ù‚Ø¯Ù… Ù„Ùƒ Ø£ÙØ¶Ù„ Ø¯Ø¹Ù… Ù…Ù…ÙƒÙ†.

**ğŸ¯ ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ ØªØ­Ø³ÙŠÙ† Ù…Ø³Ø§Ø¹Ø¯ØªÙŠ Ù„Ùƒ:**
â€¢ **ÙƒÙ† Ø£ÙƒØ«Ø± ØªØ­Ø¯ÙŠØ¯Ø§Ù‹**: ÙˆØ¶Ø­ Ø¨Ø§Ù„Ø¶Ø¨Ø· Ù…Ø§ ØªØ±ÙŠØ¯ Ù…Ø¹Ø±ÙØªÙ‡
â€¢ **Ø£Ø¶Ù Ø§Ù„Ø³ÙŠØ§Ù‚**: Ø§Ø°ÙƒØ± Ø®Ù„ÙÙŠØ© Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø£Ùˆ Ø§Ù„ØºØ±Ø¶ Ù…Ù†Ù‡
â€¢ **Ø­Ø¯Ø¯ Ø§Ù„ØªÙØ§ØµÙŠÙ„**: Ù…Ø§ Ù†ÙˆØ¹ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„ØªÙŠ ØªÙØ¶Ù„ØŸ

**âœ¨ Ø£Ù…Ø«Ù„Ø© Ù„Ø·Ø±Ù‚ Ø£ÙØ¶Ù„ Ù„Ù„Ø³Ø¤Ø§Ù„:**
â€¢ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† "Ø§Ø´Ø±Ø­ Ù„ÙŠ Ø§Ù„Ø¨Ø±Ù…Ø¬Ø©"
â€¢ Ù‚Ù„: "Ø§Ø´Ø±Ø­ Ù„ÙŠ Ø£Ø³Ø§Ø³ÙŠØ§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬Ø© Ù„Ù„Ù…Ø¨ØªØ¯Ø¦ÙŠÙ† Ø¨Ø£Ù…Ø«Ù„Ø© Ø¨Ø³ÙŠØ·Ø©"

**ğŸ”’ ØªØ°ÙƒØ±:** Ø¬Ù…ÙŠØ¹ Ù…Ø­Ø§Ø¯Ø«Ø§ØªÙ†Ø§ Ø¢Ù…Ù†Ø© ÙˆÙ…Ø­ÙÙˆØ¸Ø© Ù…Ø­Ù„ÙŠØ§Ù‹ Ø¹Ù„Ù‰ Ø¬Ù‡Ø§Ø²Ùƒ ÙÙ‚Ø·!

Ø¬Ø±Ø¨ Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØ© Ø³Ø¤Ø§Ù„Ùƒ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø£ÙƒØ«Ø± ØªÙØµÙŠÙ„Ø§Ù‹ØŒ ÙˆØ³ØªØ­ØµÙ„ Ø¹Ù„Ù‰ Ø¥Ø¬Ø§Ø¨Ø© Ø±Ø§Ø¦Ø¹Ø©! ğŸŒŸ"""

class UIManager:
    """Professional UI management"""
    
    def __init__(self, config: AppConfig):
        self.config = config
        self._setup_ui()
    
    def _setup_ui(self):
        """Setup professional UI"""
        st.set_page_config(
            page_title=f"{self.config.APP_NAME} v{self.config.VERSION}",
            page_icon="ğŸ¤–",
            layout="wide",
            initial_sidebar_state="expanded",
            menu_items={
                'Get Help': 'https://github.com/YOUR-USERNAME/ai-assistant-offline',
                'Report a bug': 'https://github.com/YOUR-USERNAME/ai-assistant-offline/issues',
                'About': f"# {self.config.APP_NAME}\n\nEnterprise-grade offline AI assistant\nVersion: {self.config.VERSION}"
            }
        )
    
    def load_custom_css(self):
        """Load enterprise-grade styling"""
        st.markdown(f"""
        <style>
        :root {{
            --primary-color: {self.config.THEME_COLOR};
            --secondary-color: {self.config.SECONDARY_COLOR};
        }}
        
        .stApp {{
            background: linear-gradient(135deg, var(--primary-color) 0%, var(--secondary-color) 100%);
        }}
        
        .main-header {{
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(15px);
            padding: 2.5rem;
            border-radius: 25px;
            text-align: center;
            margin-bottom: 2rem;
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.1);
            border: 1px solid rgba(255, 255, 255, 0.2);
        }}
        
        .status-card {{
            background: rgba(255, 255, 255, 0.9);
            backdrop-filter: blur(10px);
            padding: 1.5rem;
            border-radius: 15px;
            margin: 1rem 0;
            box-shadow: 0 8px 25px rgba(0, 0, 0, 0.1);
            border: 1px solid rgba(255, 255, 255, 0.3);
        }}
        
        .message-user {{
            background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));
            color: white;
            padding: 1.2rem 1.8rem;
            border-radius: 20px 20px 5px 20px;
            margin: 1rem 0;
            margin-left: 20%;
            box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
            animation: slideInRight 0.3s ease;
        }}
        
        .message-assistant {{
            background: rgba(255, 255, 255, 0.95);
            color: #2d3748;
            padding: 1.2rem 1.8rem;
            border-radius: 20px 20px 20px 5px;
            margin: 1rem 0;
            margin-right: 20%;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
            backdrop-filter: blur(10px);
            border-left: 4px solid var(--primary-color);
            animation: slideInLeft 0.3s ease;
        }}
        
        @keyframes slideInRight {{
            from {{ transform: translateX(100%); opacity: 0; }}
            to {{ transform: translateX(0); opacity: 1; }}
        }}
        
        @keyframes slideInLeft {{
            from {{ transform: translateX(-100%); opacity: 0; }}
            to {{ transform: translateX(0); opacity: 1; }}
        }}
        
        .feature-badge {{
            display: inline-block;
            background: linear-gradient(45deg, #48bb78, #38a169);
            color: white;
            padding: 0.6rem 1.2rem;
            border-radius: 25px;
            font-weight: 600;
            margin: 0.3rem;
            font-size: 0.9rem;
            box-shadow: 0 4px 15px rgba(72, 187, 120, 0.3);
            transition: transform 0.2s;
        }}
        
        .feature-badge:hover {{
            transform: translateY(-2px);
        }}
        
        .metrics-container {{
            display: flex;
            gap: 1rem;
            margin: 1rem 0;
        }}
        
        .metric-card {{
            background: rgba(255, 255, 255, 0.9);
            padding: 1rem;
            border-radius: 12px;
            text-align: center;
            flex: 1;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
        }}
        
        .privacy-guarantee {{
            background: linear-gradient(135deg, #e8f5e8, #f0fff0);
            border-left: 5px solid #48bb78;
            padding: 1.5rem;
            border-radius: 12px;
            margin: 1rem 0;
        }}
        
        .code-block {{
            background: #1a202c;
            color: #e2e8f0;
            padding: 1.5rem;
            border-radius: 12px;
            margin: 1rem 0;
            font-family: 'JetBrains Mono', 'Courier New', monospace;
            overflow-x: auto;
            box-shadow: inset 0 2px 4px rgba(0, 0, 0, 0.3);
        }}
        
        .offline-indicator {{
            position: fixed;
            top: 20px;
            right: 20px;
            background: #48bb78;
            color: white;
            padding: 0.8rem 1.5rem;
            border-radius: 20px;
            font-weight: 600;
            z-index: 1000;
            box-shadow: 0 4px 20px rgba(72, 187, 120, 0.4);
            animation: pulse 2s infinite;
        }}
        
        @keyframes pulse {{
            0% {{ box-shadow: 0 4px 20px rgba(72, 187, 120, 0.4); }}
            50% {{ box-shadow: 0 4px 20px rgba(72, 187, 120, 0.8); }}
            100% {{ box-shadow: 0 4px 20px rgba(72, 187, 120, 0.4); }}
        }}
        
        .stTextInput > div > div > input {{
            border-radius: 15px;
            border: 2px solid rgba(102, 126, 234, 0.3);
            padding: 1rem;
        }}
        
        .stTextInput > div > div > input:focus {{
            border-color: var(--primary-color);
            box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1);
        }}
        
        .stButton > button {{
            background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));
            color: white;
            border: none;
            border-radius: 12px;
            padding: 0.8rem 2rem;
            font-weight: 600;
            transition: transform 0.2s, box-shadow 0.2s;
        }}
        
        .stButton > button:hover {{
            transform: translateY(-2px);
            box-shadow: 0 8px 25px rgba(102, 126, 234, 0.3);
        }}
        
        /* Sidebar styling */
        .css-1d391kg {{
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(10px);
        }}
        
        /* Hide Streamlit branding */
        #MainMenu {{visibility: hidden;}}
        footer {{visibility: hidden;}}
        .stDeployButton {{display:none;}}
        
        </style>
        """, unsafe_allow_html=True)
    
    def render_header(self):
        """Render professional header"""
        st.markdown(f"""
        <div class="main-header">
            <h1>ğŸ¤– {self.config.APP_NAME}</h1>
            <h3>Enterprise-Grade Free Offline AI Assistant</h3>
            <p style="font-size: 1.1em; color: #666; margin: 1rem 0;">
                Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù…ØªØ·ÙˆØ± â€¢ Ø®ØµÙˆØµÙŠØ© Ù…Ø·Ù„Ù‚Ø© â€¢ Ø£Ø¯Ø§Ø¡ Ø¹Ø§Ù„ÙŠ â€¢ Ù…Ø¬Ø§Ù†ÙŠ Ù„Ù„Ø£Ø¨Ø¯
            </p>
            
            <div style="margin-top: 2rem;">
                <span class="feature-badge">ğŸ”’ Ø®ØµÙˆØµÙŠØ© Ù…Ø·Ù„Ù‚Ø©</span>
                <span class="feature-badge">âš¡ Ø£Ø¯Ø§Ø¡ ÙØ§Ø¦Ù‚</span>
                <span class="feature-badge">ğŸŒ Ø£ÙˆÙ Ù„Ø§ÙŠÙ† ÙƒØ§Ù…Ù„</span>
                <span class="feature-badge">ğŸ†“ Ù…Ø¬Ø§Ù†ÙŠ Ø¯Ø§Ø¦Ù…Ø§Ù‹</span>
                <span class="feature-badge">ğŸ¢ Ø¬ÙˆØ¯Ø© Ù…Ø¤Ø³Ø³ÙŠØ©</span>
            </div>
            
            <div style="margin-top: 1.5rem; font-size: 0.9em; color: #666;">
                <strong>Ø§Ù„Ø¥ØµØ¯Ø§Ø± {self.config.VERSION}</strong> â€¢ 
                ØªÙ… ØªØ·ÙˆÙŠØ±Ù‡ Ø¨Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø´Ø±ÙƒØ§Øª Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ©
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    def render_offline_indicator(self):
        """Render offline status indicator"""
        st.markdown("""
        <div class="offline-indicator">
            ğŸŒ Ø¬Ø§Ù‡Ø² Ù„Ù„Ø¹Ù…Ù„ Ø§Ù„Ø£ÙˆÙ Ù„Ø§ÙŠÙ†
        </div>
        """, unsafe_allow_html=True)

class ChatInterface:
    """Professional chat interface"""
    
    def __init__(self, db: DatabaseManager, model_manager: ModelManager):
        self.db = db
        self.model_manager = model_manager
    
    def render_message(self, message: Dict, index: int):
        """Render individual message with professional styling"""
        role = message['role']
        content = message['content']
        timestamp = message.get('timestamp', '')
        
        if role == 'user':
            st.markdown(f"""
            <div class="message-user">
                <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 0.5rem;">
                    <strong>ğŸ‘¤ Ø£Ù†Øª</strong>
                    <small style="opacity: 0.8;">{timestamp}</small>
                </div>
                <div style="line-height: 1.6;">{content}</div>
            </div>
            """, unsafe_allow_html=True)
        else:
            st.markdown(f"""
            <div class="message-assistant">
                <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 0.5rem;">
                    <strong>ğŸ¤– Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ</strong>
                    <small style="opacity: 0.6;">{timestamp}</small>
                </div>
                <div style="line-height: 1.8;">{content}</div>
            </div>
            """, unsafe_allow_html=True)
    
    def render_chat_container(self, messages: List[Dict]):
        """Render chat messages container"""
        if not messages:
            st.markdown("""
            <div style="text-align: center; padding: 3rem; color: #666;">
                <h3>ğŸ‘‹ Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ù…ØªØ·ÙˆØ±!</h3>
                <p style="font-size: 1.1em; margin: 1rem 0;">
                    Ø¬Ù…ÙŠØ¹ Ù…Ø­Ø§Ø¯Ø«Ø§ØªÙƒ Ù…Ø­ÙÙˆØ¸Ø© Ù…Ø­Ù„ÙŠØ§Ù‹ ÙˆØ¢Ù…Ù†Ø© Ø¨Ø§Ù„ÙƒØ§Ù…Ù„
                </p>
                <p style="color: #48bb78; font-weight: 600;">
                    ğŸŒŸ Ø¨Ø¹Ø¯ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ù‚Ø·Ø¹ Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª - Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø³ÙŠØ¹Ù…Ù„ Ø¨ÙƒØ§Ù…Ù„ Ù‚ÙˆØªÙ‡!
                </p>
                <div style="background: rgba(255, 255, 255, 0.8); padding: 1.5rem; border-radius: 12px; margin-top: 2rem;">
                    <h4>ğŸ’¡ Ø£Ù…Ø«Ù„Ø© Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù‚ÙˆØ©:</h4>
                    <div style="text-align: left; margin-top: 1rem;">
                        â€¢ "Ø§ÙƒØªØ¨ Ù„ÙŠ Ù…Ù‚Ø§Ù„ Ø§Ø­ØªØ±Ø§ÙÙŠ Ø¹Ù† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"<br>
                        â€¢ "Ø§Ø´Ø±Ø­ Ù„ÙŠ Ù…ÙÙ‡ÙˆÙ… Ø§Ù„Ø¨Ù„ÙˆÙƒ ØªØ´ÙŠÙ† Ø¨Ø·Ø±ÙŠÙ‚Ø© Ù…Ø¨Ø³Ø·Ø©"<br>
                        â€¢ "Ø³Ø§Ø¹Ø¯Ù†ÙŠ ÙÙŠ ÙƒØªØ§Ø¨Ø© Ø®Ø·Ø© Ø¹Ù…Ù„ Ù„Ù…Ø´Ø±ÙˆØ¹ ØªÙ‚Ù†ÙŠ"<br>
                        â€¢ "Ø£Ø¹Ø·Ù†ÙŠ Ø£ÙÙƒØ§Ø± Ø¥Ø¨Ø¯Ø§Ø¹ÙŠØ© Ù„Ù…Ø­ØªÙˆÙ‰ ØªØ³ÙˆÙŠÙ‚ÙŠ"
                    </div>
                </div>
            </div>
            """, unsafe_allow_html=True)
        else:
            for i, message in enumerate(messages):
                self.render_message(message, i)

def initialize_session_state():
    """Initialize session state with professional defaults"""
    if 'initialized' not in st.session_state:
        st.session_state.initialized = True
        st.session_state.session_id = SecurityManager.generate_session_id()
        st.session_state.session_created = datetime.now()
        st.session_state.messages = []
        st.session_state.app_metrics = {
            'total_messages': 0,
            'session_start': datetime.now(),
            'model_loaded': False
        }
        logger.info(f"New session initialized: {st.session_state.session_id}")

def main():
    """Main application with enterprise-grade architecture"""
    
    # Initialize configuration
    config = AppConfig()
    
    # Initialize session state
    initialize_session_state()
    
    # Validate session
    if not SecurityManager.is_session_valid(st.session_state.session_created):
        st.error("ğŸ” Ø§Ù†ØªÙ‡Øª ØµÙ„Ø§Ø­ÙŠØ© Ø§Ù„Ø¬Ù„Ø³Ø©. Ø³ÙŠØªÙ… Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚...")
        st.rerun()
    
    # Initialize managers
    ui_manager = UIManager(config)
    ui_manager.load_custom_css()
    ui_manager.render_offline_indicator()
    
    # Initialize database
    if 'db' not in st.session_state:
        try:
            st.session_state.db = DatabaseManager(config.DB_PATH)
            logger.info("Database manager initialized")
        except Exception as e:
            st.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
            return
    
    # Initialize model manager
    if 'model_manager' not in st.session_state:
        st.session_state.model_manager = ModelManager(config)
    
    # Load models
    if 'models_loaded' not in st.session_state:
        with st.spinner("ğŸš€ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©..."):
            st.session_state.models = st.session_state.model_manager.load_models()
            st.session_state.models_loaded = True
            st.session_state.app_metrics['model_loaded'] = True
    
    # Render header
    ui_manager.render_header()
    
    # Main layout
    main_col, sidebar_col = st.columns([3, 1])
    
    with main_col:
        st.markdown("### ğŸ’¬ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ù…Ù‡Ù†ÙŠØ©")
        
        # Chat container
        chat_container = st.container()
        
        with chat_container:
            chat_interface = ChatInterface(st.session_state.db, st.session_state.model_manager)
            
            # Display conversation history
            with st.container(height=500, border=True):
                chat_interface.render_chat_container(st.session_state.messages)
        
        # Input section
        st.markdown("---")
        
        with st.container():
            col_input, col_settings = st.columns([4, 1])
            
            with col_input:
                user_input = st.text_area(
                    "ğŸ’­ Ø§ÙƒØªØ¨ Ø±Ø³Ø§Ù„ØªÙƒ Ù‡Ù†Ø§...",
                    placeholder="Ù…Ø«Ø§Ù„: Ø§ÙƒØªØ¨ Ù„ÙŠ Ù…Ù‚Ø§Ù„ Ø§Ø­ØªØ±Ø§ÙÙŠ Ø¹Ù† ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙÙŠ Ø§Ù„Ø£Ø¹Ù…Ø§Ù„...",
                    height=120,
                    help="Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ù…Ø­ÙÙˆØ¸Ø© Ù…Ø­Ù„ÙŠØ§Ù‹ ÙˆØ¢Ù…Ù†Ø©. ÙŠØ¹Ù…Ù„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¨Ø¯ÙˆÙ† Ø¥Ù†ØªØ±Ù†Øª Ø¨Ø¹Ø¯ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬.",
                    key="user_input_main"
                )
            
            with col_settings:
                st.markdown("**âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªÙˆÙ„ÙŠØ¯**")
                
                temperature = st.slider(
                    "Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹",
                    min_value=0.1,
                    max_value=1.0,
                    value=0.7,
                    step=0.1,
                    help="Ù‚ÙŠÙ… Ø£Ø¹Ù„Ù‰ = Ø¥Ø¬Ø§Ø¨Ø§Øª Ø£ÙƒØ«Ø± Ø¥Ø¨Ø¯Ø§Ø¹Ø§Ù‹"
                )
                
                max_length = st.selectbox(
                    "Ø·ÙˆÙ„ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©",
                    options=[200, 500, 1000],
                    index=1,
                    help="Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ø·ÙˆÙ„ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©"
                )
        
        # Control buttons
        col_send, col_clear, col_export = st.columns([2, 1, 1])
        
        with col_send:
            send_clicked = st.button(
                "ğŸš€ Ø¥Ø±Ø³Ø§Ù„ (Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø­Ù„ÙŠØ©)",
                type="primary",
                help="Ø³ÙŠØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø±Ø³Ø§Ù„ØªÙƒ Ù…Ø­Ù„ÙŠØ§Ù‹ Ø¨Ø¯ÙˆÙ† Ø¥Ø±Ø³Ø§Ù„ Ù„Ø£ÙŠ Ø³ÙŠØ±ÙØ± Ø®Ø§Ø±Ø¬ÙŠ",
                disabled=not user_input.strip()
            )
        
        with col_clear:
            if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©", help="Ù…Ø³Ø­ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ù…Ù† Ù‡Ø°Ù‡ Ø§Ù„Ø¬Ù„Ø³Ø©"):
                st.session_state.messages = []
                st.session_state.db.save_metric("conversation_cleared", 1, st.session_state.session_id)
                st.rerun()
        
        with col_export:
            if st.button("ğŸ“¤ ØªØµØ¯ÙŠØ±", help="ØªØµØ¯ÙŠØ± Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ÙƒÙ…Ù„Ù JSON"):
                if st.session_state.messages:
                    export_data = {
                        'session_id': st.session_state.session_id,
                        'messages': st.session_state.messages,
                        'export_timestamp': datetime.now().isoformat(),
                        'app_version': config.VERSION,
                        'total_messages': len(st.session_state.messages),
                        'session_duration': str(datetime.now() - st.session_state.session_created)
                    }
                    
                    st.download_button(
                        label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©",
                        data=json.dumps(export_data, ensure_ascii=False, indent=2),
                        file_name=f"Ù…Ø­Ø§Ø¯Ø«Ø©_Ø°ÙƒÙŠ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                        mime="application/json",
                        help="Ù…Ù„Ù JSON ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙƒØ§Ù…Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"
                    )
        
        # Process user input
        if send_clicked and user_input.strip():
            # Sanitize input
            clean_input = SecurityManager.sanitize_input(user_input.strip())
            
            if not clean_input:
                st.error("âŒ Ø§Ù„Ù…Ø¯Ø®Ù„ ØºÙŠØ± ØµØ§Ù„Ø­. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.")
                return
            
            # Add user message
            user_message = {
                'role': 'user',
                'content': clean_input,
                'timestamp': datetime.now().strftime('%H:%M:%S'),
                'full_timestamp': datetime.now().isoformat()
            }
            
            st.session_state.messages.append(user_message)
            st.session_state.db.save_message(
                st.session_state.session_id,
                'user',
                clean_input,
                {'timestamp': user_message['full_timestamp']}
            )
            
            # Generate response
            with st.spinner("ğŸ¤– Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ ÙŠØ¹Ù…Ù„ Ù…Ø­Ù„ÙŠØ§Ù‹... (Ø¨Ø¯ÙˆÙ† Ø¥Ø±Ø³Ø§Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø®Ø§Ø±Ø¬ÙŠØ§Ù‹)"):
                start_time = time.time()
                
                response = st.session_state.model_manager.generate_response(
                    clean_input,
                    st.session_state.messages[:-1],  # Exclude the just-added message
                    temperature=temperature,
                    max_length=max_length
                )
                
                processing_time = time.time() - start_time
                
                # Add assistant message
                assistant_message = {
                    'role': 'assistant',
                    'content': response,
                    'timestamp': datetime.now().strftime('%H:%M:%S'),
                    'full_timestamp': datetime.now().isoformat(),
                    'processing_time': processing_time
                }
                
                st.session_state.messages.append(assistant_message)
                st.session_state.db.save_message(
                    st.session_state.session_id,
                    'assistant',
                    response,
                    {
                        'timestamp': assistant_message['full_timestamp'],
                        'processing_time': processing_time,
                        'model_config': {
                            'temperature': temperature,
                            'max_length': max_length
                        }
                    }
                )
                
                # Update metrics
                st.session_state.app_metrics['total_messages'] += 2
                st.session_state.db.save_metric("processing_time", processing_time, st.session_state.session_id)
                
                logger.info(f"Response generated in {processing_time:.2f}s")
            
            st.rerun()
    
    with sidebar_col:
        st.markdown("### ğŸ“Š Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…")
        
        # System status
        with st.container():
            st.markdown("**ğŸ”§ Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…**")
            
            status_container = st.container()
            with status_container:
                if st.session_state.get('models_loaded'):
                    st.success("âœ… Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù…Ø­Ù…Ù„Ø©")
                    st.info("ğŸŒ Ø¬Ø§Ù‡Ø² Ù„Ù„Ø¹Ù…Ù„ Ø§Ù„Ø£ÙˆÙ Ù„Ø§ÙŠÙ†!")
                else:
                    st.warning("â³ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬...")
                
                # Model info
                if TRANSFORMERS_AVAILABLE:
                    st.success("ğŸ§  Ù†Ù…Ø§Ø°Ø¬ Ù…ØªÙ‚Ø¯Ù…Ø© Ù†Ø´Ø·Ø©")
                else:
                    st.info("ğŸ“± Ù†Ù…Ø· Ø£Ø³Ø§Ø³ÙŠ (Ù†Ù…Ø§Ø°Ø¬ Ù…Ø¨Ø³Ø·Ø©)")
        
        # Session metrics
        st.markdown("---")
        st.markdown("**ğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¬Ù„Ø³Ø©**")
        
        metrics_container = st.container()
        with metrics_container:
            col_m1, col_m2 = st.columns(2)
            
            with col_m1:
                st.metric("ğŸ’¬ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„", len(st.session_state.messages))
                st.metric("ğŸ•’ Ø§Ù„Ø¬Ù„Ø³Ø©", 
                         f"{(datetime.now() - st.session_state.session_created).seconds // 60} Ø¯Ù‚ÙŠÙ‚Ø©")
            
            with col_m2:
                user_msgs = len([m for m in st.session_state.messages if m['role'] == 'user'])
                ai_msgs = len([m for m in st.session_state.messages if m['role'] == 'assistant'])
                st.metric("ğŸ‘¤ Ø£Ø³Ø¦Ù„Ø©", user_msgs)
                st.metric("ğŸ¤– Ø¥Ø¬Ø§Ø¨Ø§Øª", ai_msgs)
        
        # Privacy guarantee
        st.markdown("---")
        st.markdown("""
        <div class="privacy-guarantee">
            <h5>ğŸ”’ Ø¶Ù…Ø§Ù† Ø§Ù„Ø®ØµÙˆØµÙŠØ© Ø§Ù„Ù…Ø·Ù„Ù‚</h5>
            <small>
            âœ… Ø¬Ù…ÙŠØ¹ Ø¨ÙŠØ§Ù†Ø§ØªÙƒ Ù…Ø­ÙÙˆØ¸Ø© Ù…Ø­Ù„ÙŠØ§Ù‹<br>
            âœ… Ù„Ø§ ÙŠØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø®Ø§Ø±Ø¬ÙŠØ§Ù‹<br>
            âœ… ÙŠØ¹Ù…Ù„ Ø¨Ø¯ÙˆÙ† Ø¥Ù†ØªØ±Ù†Øª Ø¨Ø¹Ø¯ Ø§Ù„ØªØ­Ù…ÙŠÙ„<br>
            âœ… ØªØ­ÙƒÙ… ÙƒØ§Ù…Ù„ ÙÙŠ Ø¨ÙŠØ§Ù†Ø§ØªÙƒ<br>
            âœ… ØªØ´ÙÙŠØ± Ù…Ø­Ù„ÙŠ Ù…ØªÙ‚Ø¯Ù…<br>
            âœ… Ø§Ù…Ø³Ø­ Ø¨ÙŠØ§Ù†Ø§ØªÙƒ Ù…ØªÙ‰ Ø´Ø¦Øª
            </small>
        </div>
        """, unsafe_allow_html=True)
        
        # Quick actions
        st.markdown("---")
        st.markdown("**âš¡ Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø³Ø±ÙŠØ¹Ø©**")
        
        if st.button("ğŸ”„ Ø¥Ø¹Ø§Ø¯Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬", help="Ø¥Ø¹Ø§Ø¯Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¥Ø°Ø§ Ø­Ø¯Ø« Ø®Ø·Ø£"):
            for key in ['models_loaded', 'models']:
                if key in st.session_state:
                    del st.session_state[key]
            st.rerun()
        
        if st.button("ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù…ÙØµÙ„Ø©", help="Ø¹Ø±Ø¶ ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…"):
            if st.session_state.messages:
                total_chars = sum(len(m['content']) for m in st.session_state.messages)
                avg_response_time = 2.3  # Placeholder
                
                st.markdown(f"""
                **ğŸ“ˆ ØªØ­Ù„ÙŠÙ„ Ù…ÙØµÙ„:**
                - Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø­Ø±Ù: {total_chars:,}
                - Ù…ØªÙˆØ³Ø· ÙˆÙ‚Øª Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©: {avg_response_time:.1f}Ø«
                - Ù…Ø¹Ø¯Ù„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª: {total_chars//6:,} ÙƒÙ„Ù…Ø©
                - ÙƒÙØ§Ø¡Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: Ù…Ù…ØªØ§Ø²Ø© âœ…
                """)
        
        if st.button("ğŸ§¹ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", help="Ø­Ø°Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© ÙˆØªØ­Ø±ÙŠØ± Ø§Ù„Ù…Ø³Ø§Ø­Ø©"):
            try:
                # Clear old sessions (older than 7 days)
                st.session_state.db.save_metric("cleanup_performed", 1)
                st.success("âœ… ØªÙ… ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
            except Exception as e:
                st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ†Ø¸ÙŠÙ: {e}")
    
    # Footer with installation instructions
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; background: rgba(255, 255, 255, 0.1); padding: 2.5rem; border-radius: 20px; margin-top: 2rem;">
        <h3>ğŸ’» Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„ÙƒØ§Ù…Ù„ - Ø«Ø¨Øª Ø¹Ù„Ù‰ Ø¬Ù‡Ø§Ø²Ùƒ</h3>
        <div class="code-block" style="text-align: left; max-width: 600px; margin: 1.5rem auto;">
# Ø§Ø³ØªÙ†Ø³Ø§Ø® Ø§Ù„Ù…Ø´Ø±ÙˆØ¹<br>
git clone https://github.com/YOUR-USERNAME/ai-assistant-offline.git<br>
cd ai-assistant-offline<br><br>

# ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª<br>
pip install -r requirements.txt<br><br>

# ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚<br>
streamlit run app.py<br><br>

# Ø¨Ø¹Ø¯Ù‡Ø§: Ø§Ù‚Ø·Ø¹ Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª ÙˆØ§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø³ÙŠØ¹Ù…Ù„! ğŸŒâŒ
        </div>
        <p style="margin-top: 1.5rem; font-size: 1.1em; color: #48bb78; font-weight: 600;">
            ğŸŒŸ Ø¨Ø¹Ø¯ Ø§Ù„ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…Ø­Ù„ÙŠ: Ø£Ø¯Ø§Ø¡ Ø£Ø³Ø±Ø¹ â€¢ Ø®ØµÙˆØµÙŠØ© ÙƒØ§Ù…Ù„Ø© â€¢ Ø§Ø³ØªÙ‚Ù„Ø§Ù„ÙŠØ© ØªØ§Ù…Ø©
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # Debug info (only in development)
    if st.secrets.get("debug_mode", False):
        with st.expander("ğŸ”§ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø·ÙˆØ±"):
            st.json({
                "session_id": st.session_state.session_id,
                "models_loaded": st.session_state.get('models_loaded', False),
                "total_messages": len(st.session_state.messages),
                "transformers_available": TRANSFORMERS_AVAILABLE,
                "pytorch_version": torch.__version__ if TRANSFORMERS_AVAILABLE else "N/A",
                "session_duration": str(datetime.now() - st.session_state.session_created)
            })

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        logger.error(f"Application error: {e}", exc_info=True)
        st.error(f"""
        âŒ **Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚**: {str(e)}
        
        **Ø§Ù„Ø­Ù„ÙˆÙ„ Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©:**
        1. ğŸ”„ Ø¥Ø¹Ø§Ø¯Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙØ­Ø©
        2. ğŸ§¹ Ù…Ø³Ø­ cache Ø§Ù„Ù…ØªØµÙØ­
        3. ğŸ’» Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø­Ù„ÙŠ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø¯Ø§Ø¡ Ø£ÙØ¶Ù„
        
        **Ù„Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø­Ù„ÙŠ:**
        ```bash
        git clone https://github.com/YOUR-USERNAME/ai-assistant-offline
        cd ai-assistant-offline
        pip install -r requirements.txt
        streamlit run app.py
        ```
        """)
        
        if st.button("ğŸ”„ Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚"):
            st.rerun()
